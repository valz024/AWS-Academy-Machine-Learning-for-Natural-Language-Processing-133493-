{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fcf7f8d",
   "metadata": {},
   "source": [
    "# Capstone Project 2025 ‚Äî Unified AWS Version\n",
    "This notebook combines working Transcribe jobs, real Amazon Comprehend key phrase extraction, and phase detection (topic modeling). Ready for AWS Academy grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bfb4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import uuid\n",
    "import time\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516bd411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_bucket = \"c176045a4549683l12324630t1w510414224130-labbucket-ymkoanalkg8l\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "transcribe = boto3.client(\"transcribe\", region_name=\"us-east-1\")\n",
    "comprehend = boto3.client(\"comprehend\", region_name=\"us-east-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a78c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = s3.list_objects_v2(Bucket=output_bucket, Prefix=\"transcribe-job-\")\n",
    "output_files = []\n",
    "\n",
    "for obj in response.get(\"Contents\", []):\n",
    "    key = obj[\"Key\"]\n",
    "    video_name = key.replace(\"transcribe-job-\", \"\").replace(\".json\", \"\")\n",
    "    output_files.append({\"Video\": video_name, \"OutputKey\": key})\n",
    "\n",
    "print(f\"‚úÖ Found {len(output_files)} Transcribe result files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6db11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_rows = []\n",
    "\n",
    "for entry in output_files:\n",
    "    key = entry[\"OutputKey\"]\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=output_bucket, Key=key)\n",
    "        data = json.loads(obj[\"Body\"].read().decode(\"utf-8\"))\n",
    "        transcript = data[\"results\"][\"transcripts\"][0][\"transcript\"]\n",
    "        data_rows.append({\"Video\": entry[\"Video\"], \"Transcription\": transcript})\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error reading {key}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(data_rows)\n",
    "print(f\"‚úÖ Loaded {len(df)} transcripts.\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0618410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"clean_text\"] = df[\"Transcription\"].apply(normalize_text)\n",
    "print(\"‚úÖ Text normalized.\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e9369",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key_rows = []\n",
    "\n",
    "print(\"üîç Starting real key-phrase extraction using Amazon Comprehend...\")\n",
    "for i, row in df.iterrows():\n",
    "    text = row[\"Transcription\"][:4500]\n",
    "    try:\n",
    "        response = comprehend.detect_key_phrases(Text=text, LanguageCode=\"en\")\n",
    "        phrases = [kp[\"Text\"] for kp in response[\"KeyPhrases\"]]\n",
    "        key_rows.append({\"Video\": row[\"Video\"], \"KeyPhrases\": phrases})\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processed {i+1}/{len(df)} transcripts...\")\n",
    "        sleep(0.25)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error on {row['Video']}: {e}\")\n",
    "        key_rows.append({\"Video\": row[\"Video\"], \"KeyPhrases\": []})\n",
    "\n",
    "df_keys = pd.DataFrame(key_rows)\n",
    "print(f\"‚úÖ Extracted key phrases for {len(df_keys)} transcripts.\")\n",
    "df_keys.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8342e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_combined = pd.merge(df, df_keys, on=\"Video\", how=\"left\")\n",
    "df_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bae7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_phrases = [p for sub in df_keys[\"KeyPhrases\"] for p in sub]\n",
    "top = Counter(all_phrases).most_common(10)\n",
    "phrases, counts = zip(*top)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.barh(phrases, counts)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top Key Phrases (Amazon Comprehend)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_s3_uri  = f\"s3://{output_bucket}/transcribe-json-input/\"\n",
    "output_s3_uri = f\"s3://{output_bucket}/comprehend-topics-output/\"\n",
    "\n",
    "data_access_role = \"arn:aws:iam::934798949390:role/service-role/c176045a4549683l12324630t1-ComprehendDataAccessRole-rq0eDXpjZoWu\"\n",
    "\n",
    "response = comprehend.start_topics_detection_job(\n",
    "    InputDataConfig={\"S3Uri\": input_s3_uri, \"InputFormat\": \"ONE_DOC_PER_FILE\"},\n",
    "    OutputDataConfig={\"S3Uri\": output_s3_uri},\n",
    "    DataAccessRoleArn=data_access_role,\n",
    "    JobName=f\"ComprehendTopics-{uuid.uuid4()}\",\n",
    "    NumberOfTopics=10\n",
    ")\n",
    "\n",
    "print(\"üöÄ Started Comprehend Topics Detection Job:\")\n",
    "print(\"Job ID:\", response[\"JobId\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416aa3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_id = response[\"JobId\"]\n",
    "\n",
    "while True:\n",
    "    status = comprehend.describe_topics_detection_job(JobId=job_id)\n",
    "    state = status[\"TopicsDetectionJobProperties\"][\"JobStatus\"]\n",
    "    print(f\"Job status: {state}\")\n",
    "    if state in (\"COMPLETED\", \"FAILED\"):\n",
    "        break\n",
    "    time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057fae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = s3.list_objects_v2(Bucket=output_bucket, Prefix=\"comprehend-topics-output/\")\n",
    "for obj in result.get(\"Contents\", []):\n",
    "    if obj[\"Key\"].endswith(\".csv\") or obj[\"Key\"].endswith(\".json\"):\n",
    "        print(\"Found:\", obj[\"Key\"])\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}